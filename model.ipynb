{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "6adccc17bbe02071d921a447ffa4708ed3ad1c6c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import jsonlines\n",
    "import re\n",
    "import json\n",
    "import nltk\n",
    "import io\n",
    "import numpy as np\n",
    "from keras.layers import Embedding\n",
    "from keras.initializers import Constant\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "daad741f9949a185c5278851637f0bab7e7b4c57"
   },
   "outputs": [],
   "source": [
    "# start - <sos> tag\n",
    "# stop - <eos> tag\n",
    "\n",
    "#split records into list of impression, findings\n",
    "def splitReports(File):\n",
    "    \n",
    "    impression_list = []\n",
    "    findings_list = []\n",
    "    \n",
    "    with open(File,'r') as file:\n",
    "        for line in file:\n",
    "            all = line\n",
    "        \n",
    "    report_list = re.findall(r'{.*?}',all)\n",
    "\n",
    "    for report in report_list:\n",
    "        obj = json.loads(report)\n",
    "        # indication_list.append(str(obj['Indication']))\n",
    "        impression_list.append('start ' + str(obj['impression']) + ' stop')\n",
    "        findings_list.append(str(obj['findings']))\n",
    "        \n",
    "    return (findings_list, impression_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "ec3a975f695b3a5a82b41014c847cf14cb0461f3"
   },
   "outputs": [],
   "source": [
    "#get vocab of indications, impression, findings\n",
    "def getVocabularySets(findings_list, impression_list):\n",
    "    # indication_vocab_set = set()\n",
    "    impression_vocab_set = set()\n",
    "    findings_vocab_set = set()\n",
    "    common_vocab_set = set()\n",
    "\n",
    "    #for item in indication_list:\n",
    "     #   for word in nltk.word_tokenize(item):\n",
    "      #      indication_vocab_set.add(word.lower())\n",
    "        \n",
    "    for item in impression_list:\n",
    "        for word in nltk.word_tokenize(item):\n",
    "            impression_vocab_set.add(word.lower())\n",
    "        \n",
    "    for item in findings_list:\n",
    "        for word in nltk.word_tokenize(item):\n",
    "            findings_vocab_set.add(word.lower())\n",
    "        \n",
    "    # common_vocab_set.update(indication_vocab_set)\n",
    "    common_vocab_set.update(impression_vocab_set)\n",
    "    common_vocab_set.update(findings_vocab_set)\n",
    "    \n",
    "    return (common_vocab_set, findings_vocab_set, impression_vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "7c60d799f7b363eab1f826019eb0282ddc87ee1e"
   },
   "outputs": [],
   "source": [
    "# get the embedding  matrix\n",
    "def loadGloVeModel(gloVe_file):\n",
    "    embedding_model = {}\n",
    "    \n",
    "    with io.open(gloVe_file, encoding = 'utf8') as f:\n",
    "        word_embeddings = f.readlines()\n",
    "        \n",
    "    for word_embedding_line in word_embeddings:\n",
    "        word_embedding = word_embedding_line.split()\n",
    "        word = word_embedding[0]\n",
    "        embedding = np.array([float(col) for col in word_embedding[1:]])\n",
    "        embedding_model[word] = embedding\n",
    "            \n",
    "    return embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "91e57d58914e00a5b15238d3e60a8225b3fcee17"
   },
   "outputs": [],
   "source": [
    "#get max sequences \n",
    "def getMaxSeq(List):\n",
    "        \n",
    "    max_len = 0\n",
    "    for item in List:\n",
    "        item_len = len(item.split())\n",
    "        if item_len > max_len:\n",
    "            max_len = item_len\n",
    "    \n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "f22a8169e27f95eca6e1f3ca463883ed6fd2e81a"
   },
   "outputs": [],
   "source": [
    "findings, impression = splitReports('reports.jsonl')\n",
    "common_vocab, findings_vocab, impression_vocab = getVocabularySets(findings, impression)\n",
    "\n",
    "common = []\n",
    "common.extend(findings)\n",
    "#common.extend(indications)\n",
    "common.extend(impression)\n",
    "\n",
    "#max_indication_len = getMaxSeq(indications)\n",
    "findings_MAXLEN = getMaxSeq(findings)\n",
    "impression_MAXLEN = getMaxSeq(impression)\n",
    "\n",
    "MAXLEN = max(findings_MAXLEN,impression_MAXLEN)\n",
    "#MAX_LEN = 100 #99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "dfb99325e47cbe50feb42a8f3ea2c36666c14414"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#embedding_model = loadGloVeModel('radglove.800M.100d.txt')\n",
    "#findings_MAXLEN\n",
    "impression_MAXLEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "317a3081e58814441368cad34e89ce72228a2c3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#embedding dimension\n",
    "#EMBEDDING_DIM = 100\n",
    "\n",
    "findings_MAXLEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "e41adc6f0924b77a4c4a9a9f533ad3dae4c4d84c"
   },
   "outputs": [],
   "source": [
    "#tokenizer = Tokenizer()\n",
    "#tokenizer.fit_on_texts(common)\n",
    "\n",
    "#word_to_index = tokenizer.word_index\n",
    "\n",
    "#indication_sequences = tokenizer.texts_to_sequences(indications)\n",
    "\n",
    "#findings_sequences = tokenizer.texts_to_sequences(findings)\n",
    "#impression_sequences = tokenizer.texts_to_sequences(impression)\n",
    "\n",
    "#indication_data = pad_sequences(indication_sequences, maxlen = MAXLEN)\n",
    "\n",
    "#findings_data = pad_sequences(findings_sequences, maxlen = MAX_LEN)\n",
    "#impression_data = pad_sequences(impression_sequences, maxlen = MAX_LEN)\n",
    "\n",
    "word_2_index = dict([(word, i) for i, word in enumerate(common_vocab)])\n",
    "\n",
    "#I_word_2_index = dict([(word, i) for i, word in enumerate(impression_vocab)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "fd347110b455a24b64b0532e5818f58b62e5bdc3"
   },
   "outputs": [],
   "source": [
    "index_2_word = {}\n",
    "for word,index in word_2_index.items():\n",
    "    index_2_word[index] = word\n",
    "    \n",
    "#I_index_2_word = {}\n",
    "#for word,index in I_word_2_index.items():\n",
    "#    I_index_2_word[index] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "1c6b605ae1459c0e6bf313391fa6e3909ba888ee"
   },
   "outputs": [],
   "source": [
    "embedding_model = loadGloVeModel('radglove.800M.100d.txt')\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "embedding_matrix = np.zeros((len(common_vocab),EMBEDDING_DIM))\n",
    "# inverse_embedding_matrix = np.zeros((EMBEDDING_DIM, len(findings_vocab)))\n",
    "\n",
    "inverse_embedding_matrix = {}\n",
    "for word,index in word_2_index.items():\n",
    "    embedding_vector = embedding_model.get(word)\n",
    "    \n",
    "    if embedding_vector is not None :\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "6eb9910aca58350a97bef6eb153bfcd51ece56bc"
   },
   "outputs": [],
   "source": [
    "# check doc.s once\n",
    "# trainable=False to prevent the weights from being updated during training\n",
    "embedding_layer = Embedding(len(common_vocab), EMBEDDING_DIM, embeddings_initializer=Constant(embedding_matrix), trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "e95e6c2ae4d6d7f07b5ccaedeb40d19939047f8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2070"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "fa26e4a6445b9be3b6684bf2274f031a9223e9bb"
   },
   "outputs": [],
   "source": [
    "findings_data = np.zeros(\n",
    "    (len(findings), findings_MAXLEN),\n",
    "    dtype='float32')\n",
    "#impression_data = np.zeros(\n",
    "#    (len(impression), impression_MAXLEN),\n",
    "#    dtype='float32')\n",
    "target_data = np.zeros(\n",
    "    (len(impression), impression_MAXLEN, len(common_vocab)),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "16cfffcd6e15616dfb944ef43c9b1628573deb9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2691, 139, 2070)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "178b2293f0180d62a66a7855094c46ba59f359fd"
   },
   "outputs": [],
   "source": [
    "def toLowerCase(findings, impression):\n",
    "    new_findings = []\n",
    "    new_impression = []\n",
    "    for sent in findings:\n",
    "        new_sent = \"\"\n",
    "        for word in sent.split():\n",
    "            new_sent = new_sent + word.lower() + ' '\n",
    "        new_findings.append(new_sent) \n",
    "\n",
    "    for sent in impression:\n",
    "        new_sent = \"\"\n",
    "        for word in sent.split():\n",
    "            new_sent = new_sent + word.lower() + ' '\n",
    "        new_impression.append(new_sent)\n",
    "        \n",
    "    return (new_findings, new_impression)\n",
    "\n",
    "findings, impression = toLowerCase(findings, impression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "e54c802b3fbe68a86adc3fa6917aea4bb8f221d4"
   },
   "outputs": [],
   "source": [
    "for i, (FINDINGS, IMPRESSION) in enumerate(zip(findings, impression)):\n",
    "    for t, word in enumerate(nltk.word_tokenize(FINDINGS)):\n",
    "        findings_data[i, t] = word_2_index[word]\n",
    "        \n",
    "    for t, word in enumerate(nltk.word_tokenize(IMPRESSION)):\n",
    "        #impression_data[i, t] = I_word_2_index[word_i]\n",
    "        \n",
    "        if t > 0:\n",
    "            target_data[i, t-1, word_2_index[word]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8e39c093ddefd469d1b507b30ba9ea444d9bbd74"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7850330f0e61a29f8867f17b53da6c3a0694dd78"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "85a4ac3a6bcdc6b3fec1b1629e5c52acc25a5186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2421 samples, validate on 270 samples\n",
      "Epoch 1/30\n",
      "2421/2421 [==============================] - 329s 136ms/step - loss: 0.4728 - val_loss: 0.3687\n",
      "Epoch 2/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.3777 - val_loss: 0.3533\n",
      "Epoch 3/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.3662 - val_loss: 0.3453\n",
      "Epoch 4/30\n",
      "2421/2421 [==============================] - 145s 60ms/step - loss: 0.3585 - val_loss: 0.3392\n",
      "Epoch 5/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.3506 - val_loss: 0.3327\n",
      "Epoch 6/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.3443 - val_loss: 0.3279\n",
      "Epoch 7/30\n",
      "2421/2421 [==============================] - 145s 60ms/step - loss: 0.3398 - val_loss: 0.3247\n",
      "Epoch 8/30\n",
      "2421/2421 [==============================] - 145s 60ms/step - loss: 0.3354 - val_loss: 0.3230\n",
      "Epoch 9/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.3319 - val_loss: 0.3199\n",
      "Epoch 10/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.3279 - val_loss: 0.3184\n",
      "Epoch 11/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.3251 - val_loss: 0.3175\n",
      "Epoch 12/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.3222 - val_loss: 0.3156\n",
      "Epoch 13/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.3189 - val_loss: 0.3147\n",
      "Epoch 14/30\n",
      "2421/2421 [==============================] - 145s 60ms/step - loss: 0.3159 - val_loss: 0.3146\n",
      "Epoch 15/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.3126 - val_loss: 0.3121\n",
      "Epoch 16/30\n",
      "2421/2421 [==============================] - 145s 60ms/step - loss: 0.3097 - val_loss: 0.3127\n",
      "Epoch 17/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.3063 - val_loss: 0.3105\n",
      "Epoch 18/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.3029 - val_loss: 0.3098\n",
      "Epoch 19/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.3001 - val_loss: 0.3097\n",
      "Epoch 20/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.2966 - val_loss: 0.3081\n",
      "Epoch 21/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.2931 - val_loss: 0.3085\n",
      "Epoch 22/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.2901 - val_loss: 0.3074\n",
      "Epoch 23/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.2871 - val_loss: 0.3070\n",
      "Epoch 24/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.2843 - val_loss: 0.3067\n",
      "Epoch 25/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.2807 - val_loss: 0.3070\n",
      "Epoch 26/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.2774 - val_loss: 0.3056\n",
      "Epoch 27/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.2739 - val_loss: 0.3055\n",
      "Epoch 28/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.2707 - val_loss: 0.3052\n",
      "Epoch 29/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.2679 - val_loss: 0.3052\n",
      "Epoch 30/30\n",
      "2421/2421 [==============================] - 146s 60ms/step - loss: 0.2645 - val_loss: 0.3052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Remove attention\n",
    "\n",
    "from keras.models import Model \n",
    "from keras.layers import Average, Input, GRU, Dense, TimeDistributed, Add, Activation, RepeatVector, Flatten, Permute, Lambda, Multiply, Concatenate\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# a ----> attention of findings encoder\n",
    "n_features = 100\n",
    "epochs = 30\n",
    "batch_size = 60\n",
    "\n",
    "##ENCODER\n",
    "encoder_inputs = Input(shape = (findings_MAXLEN,), dtype = 'float32')\n",
    "\n",
    "encoder_embeds = embedding_layer(encoder_inputs)\n",
    "\n",
    "forward_Encoder = GRU(100, return_sequences = False, return_state = True)\n",
    "backward_Encoder = GRU(100, return_sequences = False, return_state = True, go_backwards = True)\n",
    "\n",
    "forward_encoder_states, forward_h = forward_Encoder(encoder_embeds) #return state is by default True\n",
    "backward_encoder_states, backward_h = backward_Encoder(encoder_embeds)\n",
    "\n",
    "encoder_state = Concatenate()([forward_h, backward_h])\n",
    "\n",
    "state = encoder_state\n",
    "#__________#__________#__________#__________#__________#_________#__________#__________#_______________________________________________________\n",
    "\n",
    "##DECODER\n",
    "decoder_input = Input(shape = (1,len(common_vocab),), dtype = 'float32')\n",
    "\n",
    "Decoder = GRU(200, return_sequences = True, return_state = True)\n",
    "\n",
    "densor = Dense(len(common_vocab), activation = 'softmax')\n",
    "\n",
    "all_outputs = []\n",
    "input_ = decoder_input\n",
    "\n",
    "for _ in range(impression_MAXLEN):\n",
    "    \n",
    "    decoder_output, s = Decoder(input_, initial_state = state)\n",
    "    \n",
    "    output = densor(decoder_output)\n",
    "    \n",
    "    all_outputs.append(output)\n",
    "    \n",
    "    input_ = output\n",
    "    \n",
    "    state = s\n",
    "    \n",
    "decoder_outputs = Lambda(lambda x: K.concatenate(x, axis = 1))(all_outputs)\n",
    "#_________#__________#___________#__________#__________#__________#__________#__________#______________________________________________________\n",
    "\n",
    "model = Model(inputs = [encoder_inputs, decoder_input], outputs = decoder_outputs)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy')\n",
    "\n",
    "decoder_input_data = np.zeros((len(impression), 1, len(common_vocab))) \n",
    "decoder_input_data[:, 0, word_2_index['start']] = 1\n",
    "\n",
    "fit_model = model.fit([findings_data, decoder_input_data], target_data, batch_size = batch_size, epochs = epochs, verbose = 1, shuffle = True, validation_split = 0.1)\n",
    "\n",
    "#model.save('vanilla.h5')\n",
    "\n",
    "training_loss = fit_model.history['loss']\n",
    "\n",
    "epoch_range = range(1, len(training_loss) + 1)\n",
    "\n",
    "plt.plot(epoch_range, training_loss, 'r--')\n",
    "plt.legend(['Loss vs Epochs'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "a277c5e524f9fa8714c290f947ef1f221d378c03"
   },
   "outputs": [],
   "source": [
    "finding = \"Lungs are clear bilaterally with no focal infiltrate , pleural effusion , or pneumothoraces . Cardiomediastinal silhouette is within normal limits . XXXX and soft tissues are unremarkable . \"\n",
    "finding_test = ''\n",
    "for word in finding.split():\n",
    "    finding_test = finding_test + word.lower() + ' '\n",
    "\n",
    "finding_test_data = np.zeros((1, findings_MAXLEN), dtype='float32')\n",
    "\n",
    "for t, word in enumerate(nltk.word_tokenize(finding_test)):\n",
    "    finding_test_data[0, t] = word_2_index[word]\n",
    "\n",
    "sos_tag_data = np.zeros((len(impression), 1, len(common_vocab)))\n",
    "sos_tag_data[:, 0, word_2_index['start']] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "bf8e3f6b7c1140802bcdfea40171f9f541d8fa70"
   },
   "outputs": [],
   "source": [
    "x = model.predict([finding_test_data,sos_tag_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImpression(model, Finding):\n",
    "    Finding_test = ''\n",
    "    \n",
    "    IMPRESSION = ''\n",
    "    \n",
    "    for word in Finding.split():\n",
    "        Finding_test = Finding_test + word.lower() + ' '\n",
    "\n",
    "    Finding_test_data = np.zeros((1, findings_MAXLEN), dtype='float32')\n",
    "\n",
    "    for t, word in enumerate(nltk.word_tokenize(Finding_test)):\n",
    "        Finding_test_data[0, t] = word_2_index[word]\n",
    "\n",
    "    sos_tag_data = np.zeros((len(impression), 1, len(common_vocab)))\n",
    "    sos_tag_data[:, 0, word_2_index['start']] = 1\n",
    "    \n",
    "    output_seq = model.predict([Finding_test_data,sos_tag_data])\n",
    "    \n",
    "    for i in range(impression_MAXLEN):\n",
    "        sampled_word = index_2_word[np.argmax(output_seq[0,i,:])]\n",
    "        if(sampled_word == 'stop'):\n",
    "            break\n",
    "        IMPRESSION = IMPRESSION + sampled_word + ' '\n",
    "        \n",
    "    return IMPRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no acute disease . \n"
     ]
    }
   ],
   "source": [
    "finding = \"The heart is normal in size . The mediastinum is stable . XXXX sternotomy changes are again noted . The lungs are clear of focal infiltrates . There is no pleural effusion . \"\n",
    "result = getImpression(model, finding)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showTrainingLossPlot(Fit_model):\n",
    "    training_loss = Fit_model.history['loss']\n",
    "\n",
    "    epoch_range = range(1, len(training_loss) + 1)\n",
    "\n",
    "    plt.plot(epoch_range, training_loss, 'r--')\n",
    "    plt.legend(['Loss vs Epochs'])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAIABJREFUeJzt3Xl4VeW59/HvTUBmkSHikESQhooCQUmxoAiCKA4Xg55aoFq0KmJF23rk1XqsWLWtVKUeR5QqVqsi6LFSQa2zWJXRiAJaQFEDMjuCKMP9/vGsQAgJO5DsrL13fp/rWhd7PWvvnXu5MDfPbO6OiIjI7tSJOwAREUl9ShYiIpKQkoWIiCSkZCEiIgkpWYiISEJKFiIikpCShYiIJKRkISIiCSlZiIhIQnXjDqC6tGrVytu0aRN3GCIiaWXu3Llr3T070fsyJlm0adOGOXPmxB2GiEhaMbOPK/M+NUOJiEhCShYiIpKQkoWIiCSUMX0WIlIzNm/eTHFxMZs2bYo7FNkDDRo0ICcnh3r16u3V55UsRGSPFBcX07RpU9q0aYOZxR2OVIK7s27dOoqLi2nbtu1efYeaoURkj2zatImWLVsqUaQRM6Nly5ZVqg0qWYjIHlOiSD9VfWZKFiIikpCSxSefQK9e8OyzcUciIpXUpEmTuEOo0DnnnEPbtm3p0qULXbp0oUePHtX6/b17945lArKSRZMm8NprsHBh3JGISIa46aabKCoqoqioiDfeeCPucKqFkkXz5tC4MXz6adyRiEgVLFu2jD59+tC5c2f69u3LJ598AsCUKVPo2LEjBQUFHHfccQAsWLCAbt260aVLFzp37szixYt3+q7x48czevTo7ecPPPAAo0aNYsOGDZx66qkUFBTQsWNHHnvssUrHd+2113L22WfTvXt38vPzmTBhAhBGKo0ePZqOHTvSqVOnnb5z7NixdOrUiYKCAq688srt5VOmTKFbt260b9+eGTNmVOqeqszdM+Lo2rWr77UOHdxPP33vPy9SiyxcuHDngl69dj3uvDNc27Ch/OsTJ4bra9bseq0SGjduvEvZaaed5g888IC7u993330+cOBAd3fv2LGjFxcXu7v7559/7u7uo0aN8r///e/u7v7dd9/5xo0bd/qu1atXe7t27baf9+/f32fMmOGPP/64n3/++dvLv/jii13iGD58uLdp08YLCgq8oKDAhw0b5u7uY8aM8c6dO/vGjRt9zZo1npOT48uXL/fHH3/cTzjhBN+yZYuvXLnSc3NzfcWKFT59+nTv3r27b9iwwd3d161b5+7uvXr18ssuu8zd3adNm+Z9+/at1D25l/Ps3B2Y45X4HauaBUBeXui7EJG09eabbzJs2DAAzj77bF5//XUAjjnmGM455xwmTJjA1q1bAejevTt//OMfGTt2LB9//DENGzbc6buys7M59NBDeeutt1i3bh3vv/8+xxxzDJ06deL555/niiuuYMaMGTRr1qzcWEo3Qz388MPbywcOHEjDhg1p1aoVxx9/PLNmzeL1119n6NChZGVl0bp1a3r16sXs2bN54YUXOPfcc2nUqBEALVq02P49p59+OgBdu3Zl2bJllbqnqtKkPIDu3eGDD+KOQiQ9vfJKxdcaNdr99Vatdn+9GowfP56ZM2cybdo0unbtyty5cxk2bBhHH30006ZN45RTTuGee+6hT58+O31uyJAhTJ48mcMOO4zBgwdjZrRv35558+Yxffp0rr76avr27cs111xT6VjKDl/d2+Gs9evXByArK4stW7YAVOqeqkI1C4AxY+CRR+KOQkSqoEePHkyaNAmAhx9+mJ49ewKwdOlSjj76aK677jqys7P59NNP+fDDDzn00EO59NJLGThwIPPnz9/l+wYPHsxTTz3Fo48+ypAhQwBYsWIFjRo14qyzzmL06NHMmzdvj2J86qmn2LRpE+vWreOVV17hRz/6ET179uSxxx5j69atrFmzhtdee41u3brRr18/Jk6cyMaNGwFYv379br+7MvdUFapZiEja2bhxIzk5OdvPL7vsMm6//XbOPfdcbrrpJrKzs5k4cSIAo0ePZvHixbg7ffv2paCggLFjx/LQQw9Rr149DjjgAK666qpdfkbz5s3p0KEDCxcupFu3bgC8++67jB49mjp16lCvXj3uvvvucuMbPXo0N9xww/bzWbNmAdC5c2eOP/541q5dy+9+9zsOOuggBg8ezJtvvklBQQFmxp///GcOOOAA+vfvT1FREYWFheyzzz6ccsop/PGPf6zwv8nkyZMT3lNVWOjfSH+FhYW+12OP334bzjgDJk4Mcy5EpEKLFi2iQ4cOcYeRdq699lqaNGnC5ZdfHlsM5T07M5vr7oWJPqtmKIB994WPPgqHiIjsQs1QACXVWc21EJEkufbaa+MOoUpUswCoXx9at9bwWZFKypTm69qkqs9MyaKE5lqIVEqDBg1Yt26dEkYa8Wg/iwYNGuz1d6gZqsSAAbB5c9xRiKS8nJwciouLWbNmTdyhyB4o2SlvbylZlLj66rgjEEkL9erV2+vd1iR9qRmqtG3bwiEiIjtRsijxzDPQoAFU86xHEZFMoGRRolWr0GehTm4RkV0kNVmYWX8z+8DMlpjZlbt53xlm5mZWGJ23MbNvzawoOsYnM04gjIYCzbUQESlH0jq4zSwLuBPoBxQDs81sqrsvLPO+psCvgJllvmKpu3dJVny7yM4O8y1UsxAR2UUyaxbdgCXu/qG7fw9MAgaW877rgbHApiTGklidOpCbq2QhIlKOZCaLg4HSbTrFUdl2ZnYUkOvu08r5fFsze9vMXjWznkmMc4cLL4QTT6yRHyUikk5im2dhZnWAccA55Vz+DMhz93Vm1hX4h5kd4e5flfmOEcAIgLySPoeqiHE1SBGRVJbMmsVyILfUeU5UVqIp0BF4xcyWAT8GpppZobt/5+7rANx9LrAUaF/2B7j7ve5e6O6F2dnZVY942zZYuVJzLUREykhmspgN5JtZWzPbBxgCTC256O5funsrd2/j7m2At4AB7j7HzLKjDnLM7FAgH/gwibEG998PBx4IxcVJ/1EiIukkacnC3bcAo4DngEXAZHdfYGbXmdmABB8/DphvZkXA48BId9/9noLVITeqCKmTW0RkJ0nts3D36cD0MmXl7m7u7r1LvX4CeCKZsZWrpN9DyUJEZCeawV1aSc1CE/NERHaiZFFakybQooVqFiIiZWiJ8rJuuAHy8+OOQkQkpShZlHXRRXFHICKSctQMVdYXX8DcuXFHISKSUpQsyrr3XigshK+/jjsSEZGUoWRRlkZEiYjsQsmiLM21EBHZhZJFWUoWIiK7ULIo68ADIStLyUJEpBQNnS2rbl146CHo2DHuSEREUoaSRXmGDo07AhGRlKJmqPIsXQrPPht3FCIiKUPJojwTJsCAAdoESUQkomRRnrw82LwZVq2KOxIRkZSgZFEebYIkIrITJYvylMy10CxuERFAyaJ8mpgnIrITDZ0tz377wb/+BZ06xR2JiEhKULIojxn06xd3FCIiKUPNUBV54w149NG4oxARSQlKFhV54AH49a/jjkJEJCUoWVQkLw9Wr4Zvv407EhGR2ClZVKRkrkVxcbxxiIikACWLimiuhYjIdkoWFdFcCxGR7TR0tiKHHAILF0KbNnFHIiISOyWLitStCx06xB2FiEhKUDPU7kyZAvfeG3cUIiKxU7LYncceg7/8Je4oRERip2SxO3l5oYPbPe5IRERipWSxO3l5sHEjrF8fdyQiIrFSstgdDZ8VEQGULHavJFksXx5vHCIiMdPQ2d3p0gW++gqaNo07EhGRWKlmsTt16ypRiIigZJHYzTfDbbfFHYWISKyULBJ55pkw30JEpBZTskikZK6FiEgtltRkYWb9zewDM1tiZlfu5n1nmJmbWWGpst9Gn/vAzE5KZpy7lZcHK1bA5s2xhSAiErekJQszywLuBE4GDgeGmtnh5byvKfArYGapssOBIcARQH/gruj7al5uLmzbFhKGiEgtlcyaRTdgibt/6O7fA5OAgeW873pgLLCpVNlAYJK7f+fuHwFLou+reXl5sN9+sHZtLD9eRCQVJDNZHAyU3mauOCrbzsyOAnLdfdqefjb6/Agzm2Nmc9asWVM9UZfVrx98/jl07Zqc7xcRSQOxdXCbWR1gHPDfe/sd7n6vuxe6e2F2dnb1BVeaWXK+V0QkjSQzWSwHckud50RlJZoCHYFXzGwZ8GNgatTJneizNWvkSBg3LrYfLyISt2Qmi9lAvpm1NbN9CB3WU0suuvuX7t7K3du4exvgLWCAu8+J3jfEzOqbWVsgH5iVxFh3b+ZMePnl2H68iEjckrY2lLtvMbNRwHNAFnC/uy8ws+uAOe4+dTefXWBmk4GFwBbgYnffmqxYE8rLg2XLYvvxIiJxS+pCgu4+HZhepuyaCt7bu8z5H4A/JC24PZGXB6+9FncUIiKx0QzuysjNhS++gK+/jjsSEZFYKFlURn4+dOoUhtCKiNRCShaVMXgwzJ+/YzMkEZFaRslCREQSUrKoDHfo3RtuuSXuSEREYqFkURlm8NFH8M47cUciIhILJYvKysuDTz9N/D4RkQykZFFZ2gRJRGoxJYvKys0NNYtt2+KORESkxilZVNZRR4XlyjdsiDsSEZEal9TlPjLKmWeGQ0SkFlLNQkREElKyqKxvvoFDDoH//d+4IxERqXFKFpXVuDGsXx/mW4iI1DJKFpVlpuGzIlJrVSpZmFk7M6sfve5tZpea2X7JDS0F/fCH8NJLmsktIrVOZWsWTwBbzewHwL2E/bEfSVpUqeqWW6BpU/jZzzTfQkRqlcoOnd0WbZM6GLjd3W83s7eTGVhKatsWXnwRtm6FOmrBE5Hao7K/8Tab2VBgOPB0VFYvOSGluPbtoUOHsBLt2LHam1tEaoXKJotzge7AH9z9IzNrCzyUvLDSQHEx3Hgj9O0Ly5fHHY2ISFJVKlm4+0J3v9TdHzWz5kBTdx+b5NhSW24uPPccrFkTEsaqVXFHJCKSNJUdDfWKme1rZi2AecAEMxuX3NDSQLduMH16WGDwhBNg7dq4IxIRSYrKNkM1c/evgNOBB939aOCE5IWVRo49FqZODX0Xs2bFHY2ISFJUdjRUXTM7EDgT+J8kxpOe+vYNyaJly3DuHibxiYhkiMrWLK4DngOWuvtsMzsUWJy8sNJQSaJ44gk48UTYuDHeeEREqlFlO7inuHtnd78oOv/Q3c9IbmhpavPmMBdj0CDtfSEiGaOyHdw5Zvakma2OjifMLCfZwaWlIUPg/vvhhRfgyCPVjyEiGaGyzVATganAQdHxz6hMynPOOaF2sWkT9OgBH3wQd0QiIlVS2WSR7e4T3X1LdDwAZCcxrvR3/PEwfz7cdVdYgBDULCUiaauyyWKdmZ1lZlnRcRawLpmBZYT99oMRI8Lr+fPD5kl//WsYLSUikkYqmyx+QRg2uxL4DPgv4JwkxZSZWrSAggK44AIYPDjM/BYRSROVHQ31sbsPcPdsd9/f3QcBGg21J3Jy4PnnYdw4eOYZ6NQpzP4WEUkDVVln+7Jqi6K2qFMHfvMbmDMH9t8fXnst7ohERCqlsjO4y6MpynurUyeYPXvHLO833oB99oHCwnjjEhGpQFVqFuqlrYr69UOCcIfLL4fu3cOS51u3xh2ZiMgudpsszOxrM/uqnONrwnwLqSozePrpMOP7t78N60x9+mncUYmI7GS3ycLdm7r7vuUcTd29Kk1YUlqLFjB5MkycCHPnQufOmsgnIilFG0mnCrMw87uoCM47D/LzQ7nmZIhICkhqsjCz/mb2gZktMbMry7k+0szeNbMiM3vdzA6PytuY2bdReZGZjU9mnCmlXTu4+eYwcqq4OGyw9OabcUclIrVc0pKFmWUBdwInA4cDQ0uSQSmPuHsnd+8C/BkovfveUnfvEh0jkxVnSlu7Nhw9e8K118KWLXFHJCK1VDJrFt2AJdFy5t8Dk4CBpd8Q7b5XojEaYbWzLl1Cs9SwYfD734ek8e67cUclIrVQMpPFwUDpYT3FUdlOzOxiM1tKqFlcWupSWzN728xeNbOeSYwztTVrBg8+CI8+Gjq9b7st7ohEpBaKvYPb3e9093bAFcDVUfFnQJ67H0mYKf6Ime1b9rNmNsLM5pjZnDWZvtbSkCGweHGYiwFhUt+4cfD99/HGJSK1QjKTxXIgt9R5TlRWkUnAIAB3/87d10Wv5wJLgfZlP+Du97p7obsXZmfXghXTW7bcefvW//5vOOIImDpVo6ZEJKmSmSxmA/lm1tbM9gGGEDZQ2s7M8kudnkq0r7eZZUcd5ET7fecDHyYx1vRz441hIcK6dWHgQOjXLyyDLiKSBElLFu6+BRgFPAcsAia7+wIzu87MBkRvG2VmC8ysiNDcNDwqPw6YH5U/Dox09/XJijVtnXxySBC33Qbz5oWZ4CIiSWCeIc0XhYWFPmfOnLjDiM/69dCwYTieeiqMmrrgAmjdOu7IRCSFmdlcd0+4imnsHdxSTVq0CIkC4Lnn4He/g9xcGDoUZsxQn4aIVImSRSa66y5YtAh++cuw0dJxx8HZZ8cdlYikMSWLTHXYYXDrrbB8edj3e8iQUP7553DxxeoMF5E9omSR6Ro3DgsTnnZaOJ81C+6/P+wHfuyx8PDDsGlTvDGKSMpTsqhtTjop1DZuuQVWrYKzzoKDDw41DhGRCihZ1EYtWsBll4XlQ55/Hi69FJo3D9euuQbuuw+++SbeGEUkpShZ1GZ16sAJJ8CYMeF8y5YwG/z88+HAA2HEiLCsiEZSidR6ShayQ9268Pbb8O9/w09+EvozunWD22+POzIRiZmShezMDHr0CJ3gK1bA+PFhf3CAJ5+EE0+Ee+6BlSvjjVNEapSShVSsWTO48ELIywvn330HH30EI0fCQQeF+Ru33qpNmURqASULqbwhQ+A//wlLiYwZA19+CXfeCVlZ4frTT4dOcxHJOFobSqrmyy9DDWTrVth//7BG1RFHhGVGhg2Dtm3jjlBEdkNrQ0nNaNYs/JmVBe+8E1bAbdECrr4aDj0Ubrop3vhEpFooWUj1ycmBSy6B116DZcvgT38KQ3MB3nwzzCKfNAk2bow1TBHZc0oWkhyHHAJXXglHHhnOV66EoqLQPNW6Nfz852F13K1b441TRCpFyUJqxuDB8Mkn8PLL8NOfhsl/w4btSBYvvRQWN9y2Ld44RaRc6uCWeGzaFJZRL6l5HHZYGEnVqhX07g19+oStYn/wg1jDFMl06uCW1NagwY5EAfCvf8EDD8App8DMmWEvjuuvD9fc4cEHwxwPEYmFahaSetxh6dLQJNW+fZjb8cMfhmtt24ZaR9++YTZ5y5bxxiqS5lSzkPRlFpqf2rcP5/n5sGBBGJZbUACPPx76O155JVxftgz++U/46qu4IhbJeHXjDkAkITM4/PBwXHJJ6BSfN29HbWPKFPh//y/M9SgsDDWO004Lr+vo30Mi1UHNUJL+vvsuzON48cVwzJwZEse6ddC0KSxeHJZcb9Ik7khFUo6aoaT2qF8/jKC6/np44w1YvRqmTQuJAmD48NC30b8/3HFHaLYSkT2iZCGZp2XLMOy2xJ/+BKNGhdFUl1wSOslHjNhxXavmiiSkPgvJfL16heOWW8LIqmnTdixwuGZN6Ezv1Sv0dZx0Ujg3izdmkRSjZCG1S/v2O0ZZQejv+NnPwtIj//xnKGvTBv72t7Bfh4gAaoaS2i4nB+66K8zrWLIkvC4ogNzccP2hh+CYY+CGG8KWsxkyIERkTylZiJRo1w4uugj+8Y8dzVT168P338M118BRR4XkcsEFsHlzvLGK1DAlC5HdOfNMmD0bPvsMJk4M+5O//z7Uqxeu/+EPcPvt8OGH8cYpkmSaZyGyp9xDB7g7dOsGJX/vDjsMTj0VfvITOProeGMUqSTNsxBJlpKRUmah1rF4Mdx6a2iiuu22sPw6hJV1b7wxJBPt2yFpTjULkeq0YUMYYdWiRZggeMwxobxFi7AA4gknwOmnQ3Z2vHGKRFSzEIlD48YhMUDo31i5Eh5+GAYOhLfegpEjd/RvvPceTJ8eaiAiKU7JQiSZWrcOK+Tef3/YKfD996Fr13BtwoTQx9GyJQwaBPfdF5KLSApSshCpKWZhpdy60VzYsWNDzWL4cJg7F84/P2wIVdI0vHKl5nVIytAMbpG4NGgAJ58cjjvvhHfeCbWPkpFWRx8dXp92Wqh59Oq1Y8iuSA1TzUIkFZhBly4wYEA437o1TATs0iU0YfXrB/vvD/feG2+cUmspWYikorp14bzzwmzytWvhqadg8GA45JBw/b33Qo3jr3+FVavijVVqBTVDiaS6Ro1CjaOk1gGwYkXYanbatFAr6dEjNFWNHKlNniQpklqzMLP+ZvaBmS0xsyvLuT7SzN41syIze93MDi917bfR5z4ws5OSGadI2jnxxDAEt6gIxowJ8zuuumrHhMHJk+Huu2HRInWSS7VI2qQ8M8sC/gP0A4qB2cBQd19Y6j37uvtX0esBwC/dvX+UNB4FugEHAS8A7d29wmmwmpQntd6qVWGoLoSJf08+GV7vv3/oHD/5ZDj33Pjik5SUCpPyugFL3P1Dd/8emAQMLP2GkkQRaQyUZK6BwCR3/87dPwKWRN8nIhUpSRQATzwRlly/776wodNbb8GUKTuuX355WH59/fqaj1PSUjL7LA4GPi11XgzssrqamV0MXAbsA/Qp9dm3ynz24HI+OwIYAZCXl1ctQYtkBLOw5Hq7dvCLX4SmqA0bwrVvv4VJk8LOgVlZodYxaFCojRy8y/9mIkAKjIZy9zvdvR1wBXD1Hn72XncvdPfCbK21I1Ixsx0d3w0bhvkcs2bBFVeEyX+XXrpjp8DPPw+jrdTXIaUkM1ksB3JLnedEZRWZBAzay8+KyJ6oUwd+9KOwH8eCBfDBB/DTn4Zrjz8OnTpBfn5orvr3v2HbtnjjldglM1nMBvLNrK2Z7QMMAaaWfoOZ5Zc6PRVYHL2eCgwxs/pm1hbIB2YlMVaR2q19e2jePLweMADuuSeU3X47HHtsWH79q692/x2S0ZLWZ+HuW8xsFPAckAXc7+4LzOw6YI67TwVGmdkJwGbgc2B49NkFZjYZWAhsAS7e3UgoEalGrVvDiBHh+OqrsH5VURHsu2+4fu65YYb56aeHIbyNGsUbr9QI7WchInvmoovgscdC30ajRtC/f1gE8eST445M9kIqDJ0VkUx0991hTscLL8A558Cbb8LMmeHahg2hH2T2bO0OmGFUsxCRqtm2LWzg1KgRzJgBxx0Xylu0CDsD9usX1rVq2TLeOKVcqlmISM2oU2dHv0XPnrB6NTzySOgof/11uOAC+PjjcL2oCJ5+Gr7+Or54Za9oIUERqV7Z2TB0aDjcYeFC6NAhXJswAe66K6yq2737jprHj3+8Y10rSUlqhhKRmrNpU5i38cIL8PzzMG8eHHQQfPppSBYvvAC5uWHYrpJHjahsM5SShYjEZ+1a+OijMEHQPSSK5cvDn/36hZpHnz47r3sl1Up9FiKS+lq1CokCQk3i1Vdh/Hjo1i2smjtsGPz+9+H61q1hSZIvvogv3lpMfRYikjpKFj+88MKQHObNg6ZNw7V33gmd5nXqQGFhqHH06RNmmDdsGG/ctYBqFiKSmrKyQq3jsMPC+RFHwCuvwP/8D9SrBzffHGaQv/pquL5iRViWXZJCyUJE0kP9+mE59euuC0NyP/88LEXSs2e4ftddYfHDggK4/vowCkuqjZKFiKSnJk3CEiONG4fzCy+Ev/wlNFuNGRNqIoWFWjG3mqjPQkQyQ24u/PrX4fjss9BBvnZt6OOAsPDhD34AZ5wRmrfq6N/Ke0L/tUQk8xx4IPzyl3DNNeF80ybYuDHUPH784zC347zzwnazUilKFiKS+Ro0gGefDUuR/P3vcPzxYZ/yRYvC9eXL4Y47YNmyWMNMZZqUJyK10+bNoT+jfn148EEYPjyUH3EEnHZaOLp3D6OyMpgm5YmI7E69eiFRAPz852Fr2XHjwmzxW24Jq+euWROuf/xxaMaqxZQsREQgrEf1m9/Aiy+GjvHnnoMDDgjXRo4Ms80HDoSJE3ckkVpEyUJEpKxmzcLaVCWuuCJ0iL/9NvziFyGJXHRRfPHFQENnRUQS6d07HLfdFhLGU09Bmzbh2jffhGsnnACnnhr6Oepm3q/WzLsjEZFkMYOjjgpHiVWrYN99Qz/H2LHQvDmcdBJcdRV06hRfrNVMzVAiIlXRrh289FLo55gyBQYNgpdf3jFz/NVX4YYbQo0kjUefauisiEh127Yt1ELMwjpVY8aERHHggWHxw+OPh7POSolhudr8SEQkVaxaBc88A9OmhVpH48ZhAqBZ2Gq2YcOQQA4+uMZDU7IQEUlF27aFtatKEkPHjrBgQXidnx86y08/Hfr3r5FwNClPRCQV1amzcw3inXfCJk/jxoW9OyZPDjUQCBtA3XQTvPde7P0dqlmIiKSSrVthw4YwwqqoCI48MpS3axcmBQ4aBD16VFt/h2oWIiLpKCsrJAqALl3CIofjx4cmqjvuCMuQvPRSuL5+fY0tQ6JkISKSyg46KGzs9MwzYZmRxx4LOwZCaKI66KCwBHuSaVKeiEi62HdfOPPMHecDBoT+jwYNkv6jlSxERNJV9+7hqAFqhhIRkYSULEREJCElCxERSUjJQkREElKyEBGRhJQsREQkISULERFJSMlCREQSypiFBM1sDfBxmeJWwNoYwkmmTLsn3U/qy7R7yrT7gard0yHunp3oTRmTLMpjZnMqs5piOsm0e9L9pL5Mu6dMux+omXtSM5SIiCSkZCEiIgllerK4N+4AkiDT7kn3k/oy7Z4y7X6gBu4po/ssRESkemR6zUJERKpBxiYLM+tvZh+Y2RIzuzLueKrKzJaZ2btmVmRmabnZuJndb2arzey9UmUtzOx5M1sc/dk8zhj3RAX3c62ZLY+eU5GZnRJnjHvCzHLN7GUzW2hmC8zsV1F5Oj+jiu4pLZ+TmTUws1lm9k50P7+Pytua2czo991jZrZPtf/sTGyGMrMs4D9AP6AYmA0MdfeFsQZWBWa2DCiG+9P1AAAEgklEQVR097QdH25mxwHfAA+6e8eo7M/Aene/MUrqzd39ijjjrKwK7uda4Bt3vznO2PaGmR0IHOju88ysKTAXGAScQ/o+o4ru6UzS8DmZmQGN3f0bM6sHvA78CrgM+D93n2Rm44F33P3u6vzZmVqz6AYscfcP3f17YBIwMOaYaj13fw1YX6Z4IPC36PXfCP8jp4UK7idtuftn7j4vev01sAg4mPR+RhXdU1ry4JvotF50ONAHeDwqT8ozytRkcTDwaanzYtL4L0jEgX+Z2VwzGxF3MNWotbt/Fr1eCbSOM5hqMsrM5kfNVGnTZFOambUBjgRmkiHPqMw9QZo+JzPLMrMiYDXwPLAU+MLdt0RvScrvu0xNFpnoWHc/CjgZuDhqAskoHtpE071d9G6gHdAF+Ay4Jd5w9pyZNQGeAH7t7l+Vvpauz6ice0rb5+TuW929C5BDaEU5rCZ+bqYmi+VAbqnznKgsbbn78ujP1cCThL8kmWBV1K5c0r68OuZ4qsTdV0X/M28DJpBmzylqB38CeNjd/y8qTutnVN49pftzAnD3L4CXge7AfmZWN7qUlN93mZosZgP50QiBfYAhwNSYY9prZtY46pzDzBoDJwLv7f5TaWMqMDx6PRx4KsZYqqzkl2pkMGn0nKLO0/uARe4+rtSltH1GFd1Tuj4nM8s2s/2i1w0Jg3gWEZLGf0VvS8ozysjRUADRULhbgSzgfnf/Q8wh7TUzO5RQmwCoCzySjvdjZo8CvQkrZK4CxgD/ACYDeYRVg89097ToNK7gfnoTmjYcWAZcWKq9P6WZ2bHADOBdYFtUfBWhjT9dn1FF9zSUNHxOZtaZ0IGdRfjH/mR3vy76HTEJaAG8DZzl7t9V68/O1GQhIiLVJ1OboUREpBopWYiISEJKFiIikpCShYiIJKRkISIiCSlZiCRgZltLrU5aVJ2rGJtZm9Kr1oqkqrqJ3yJS630bLa8gUmupZiGyl6I9Rv4c7TMyy8x+EJW3MbOXokXqXjSzvKi8tZk9Ge1F8I6Z9Yi+KsvMJkT7E/wrmpmLmV0a7cMw38wmxXSbIoCShUhlNCzTDPXTUte+dPdOwB2EFQMAbgf+5u6dgYeB26Ly24BX3b0AOApYEJXnA3e6+xHAF8AZUfmVwJHR94xM1s2JVIZmcIskYGbfuHuTcsqXAX3c/cNosbqV7t7SzNYSNtzZHJV/5u6tzGwNkFN6GYZo2ezn3T0/Or8CqOfuN5jZs4TNlf4B/KPUPgYiNU41C5Gq8Qpe74nSa/hsZUdf4qnAnYRayOxSq4qK1DglC5Gq+WmpP9+MXr9BWOkY4GeEhewAXgQugu0b2DSr6EvNrA6Q6+4vA1cAzYBdajciNUX/UhFJrGG0M1mJZ929ZPhsczObT6gdDI3KLgEmmtloYA1wblT+K+BeMzuPUIO4iLDxTnmygL9HCcWA26L9C0RioT4Lkb0U9VkUuvvauGMRSTY1Q4mISEKqWYiISEKqWYiISEJKFiIikpCShYiIJKRkISIiCSlZiIhIQkoWIiKS0P8HfCgsuQ/dOrsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "showTrainingLossPlot(fit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-e6c4a7146be2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ENter n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sys_eval_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltin_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mbuiltin_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mbuiltin_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_getpass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
